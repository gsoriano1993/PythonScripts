{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "69e8925f-04b5-4c9a-ab4b-1c909abf98bc",
   "metadata": {
    "id": "69e8925f-04b5-4c9a-ab4b-1c909abf98bc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-speech in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (1.32.1)\n",
      "Requirement already satisfied: librosa in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (0.56.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.39.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: pydub in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-speech\n",
    "!pip install librosa\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "005eb3fe-143a-468f-99a1-c15d2d08bca0",
   "metadata": {
    "id": "005eb3fe-143a-468f-99a1-c15d2d08bca0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "99c5e28b-a9fc-4fe6-9c95-5e3fdf3aa5c8",
   "metadata": {
    "id": "99c5e28b-a9fc-4fe6-9c95-5e3fdf3aa5c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPEECH_KEY=\"d0c4c8a9daf64fd7bc4451ada99d8003\"\n",
    "SPEECH_REGION=\"eastus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "16635686-5725-428d-8276-88fc937ec7ac",
   "metadata": {
    "id": "16635686-5725-428d-8276-88fc937ec7ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lista_directorio=[]\n",
    "lista_directorio=!ls\n",
    "lista_archivos=[]\n",
    "\n",
    "for i in lista_directorio:\n",
    "    if(i.endswith(\".wav\")==True):\n",
    "        lista_archivos.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0c587bbf-e32b-435e-96d9-1704950cbcee",
   "metadata": {
    "id": "0c587bbf-e32b-435e-96d9-1704950cbcee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#aca se guardan los datos finales\n",
    "dfFinal=pd.DataFrame()\n",
    "lista_tiempos=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dc9fa169-1f10-46a9-b8bb-3eba94c8a3b2",
   "metadata": {
    "id": "dc9fa169-1f10-46a9-b8bb-3eba94c8a3b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Removedor de silencios\n",
    "def remover_silencios (archivo):\n",
    "    # Load the input audio file\n",
    "    input_file = archivo\n",
    "    audio = AudioSegment.from_wav(input_file)\n",
    "\n",
    "    # Define silence settings (adjust these as needed)\n",
    "    min_silence_len = 500  # Minimum silence duration in milliseconds\n",
    "    silence_thresh = -40  # Silence threshold in dBFS\n",
    "\n",
    "    # Split audio into non-silent chunks\n",
    "    audio_chunks = split_on_silence(audio, silence_thresh=silence_thresh, min_silence_len=min_silence_len)\n",
    "\n",
    "    # Create a new audio segment by concatenating non-silent chunks\n",
    "    output_audio = AudioSegment.empty()\n",
    "    for chunk in audio_chunks:\n",
    "        output_audio += chunk\n",
    "\n",
    "    # Save the cleaned audio to a new file\n",
    "    output_file = archivo\n",
    "    output_audio.export(output_file, format=\"wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f0241c4e-9961-454b-a820-ed25b1f7d08d",
   "metadata": {
    "id": "f0241c4e-9961-454b-a820-ed25b1f7d08d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SessionStarted event\n",
      "Canceled event\n",
      "CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=2e2cc7e286b84bfca9849f17b293e5be, result=ConversationTranscriptionResult(result_id=4ff7c03f0690420ca24eee3c5d1e4c42, speaker_id=, text=, reason=ResultReason.Canceled))\n",
      "SessionStopped event\n",
      "CLOSING on SessionEventArgs(session_id=2e2cc7e286b84bfca9849f17b293e5be)\n",
      "SessionStarted event\n",
      "Canceled event\n",
      "CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=17ad9348928e4201b98534de90f1bdfc, result=ConversationTranscriptionResult(result_id=6e17b94c814e4d8398dfd5a08c470dcf, speaker_id=, text=, reason=ResultReason.Canceled))\n",
      "SessionStopped event\n",
      "CLOSING on SessionEventArgs(session_id=17ad9348928e4201b98534de90f1bdfc)\n",
      "SessionStarted event\n",
      "Canceled event\n",
      "CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=0bb02dc241b248c88feb9de5c55cd846, result=ConversationTranscriptionResult(result_id=ad0dd86ee6f04714abfb39c338fad8d6, speaker_id=, text=, reason=ResultReason.Canceled))\n",
      "SessionStopped event\n",
      "CLOSING on SessionEventArgs(session_id=0bb02dc241b248c88feb9de5c55cd846)\n",
      "SessionStarted event\n",
      "Canceled event\n",
      "CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=982af9c6c46d47b6bb9832eb41492be3, result=ConversationTranscriptionResult(result_id=5cab0f9d210d4246a4ce9beea8d8f687, speaker_id=, text=, reason=ResultReason.Canceled))\n",
      "SessionStopped event\n",
      "CLOSING on SessionEventArgs(session_id=982af9c6c46d47b6bb9832eb41492be3)\n",
      "SessionStarted event\n",
      "Canceled event\n",
      "CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=9b2293f579b94de7a26ea6a342d48ff1, result=ConversationTranscriptionResult(result_id=b7dd7258da0c458dacf5a02a8911ba60, speaker_id=, text=, reason=ResultReason.Canceled))\n",
      "SessionStopped event\n",
      "CLOSING on SessionEventArgs(session_id=9b2293f579b94de7a26ea6a342d48ff1)\n"
     ]
    }
   ],
   "source": [
    "#creamos variables globales para llevar al data frame\n",
    "\n",
    "for j in lista_archivos:\n",
    "    archivo_audio = j\n",
    "    salida = []\n",
    "    aux1 = {}\n",
    "    dfAux = pd.DataFrame()\n",
    "    lista_orden = []\n",
    "    lista_aux=[]\n",
    "    #######################################################\n",
    "    #funcion para guardar tiempos de audios y remover silencios\n",
    "    original, sr = librosa.load(j)\n",
    "    tiempo_original=librosa.get_duration(y=original, sr=sr)\n",
    "    remover_silencios(j)\n",
    "    modificado, sr = librosa.load(j)\n",
    "    tiempo_sin_silencios=librosa.get_duration(y=modificado, sr=sr)\n",
    "    lista_aux=[round(tiempo_original), round(tiempo_sin_silencios), j]\n",
    "    lista_tiempos.append(lista_aux)\n",
    "    #######################################################\n",
    "    \n",
    "    def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "        print('Canceled event')\n",
    "\n",
    "    def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n",
    "        print('SessionStopped event')\n",
    "\n",
    "    def conversation_transcriber_transcribed_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        #print('TRANSCRIBED:')\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            #print('\\tText={}'.format(evt.result.text))\n",
    "            aux1 = (json.dumps({\"Text\": \"{}\".format(evt.result.text), \"Speaker\": \"{}\".format(evt.result.speaker_id)}))\n",
    "            salida.append(aux1)\n",
    "            #print('\\tSpeaker ID={}'.format(evt.result.speaker_id))\n",
    "        elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print('\\tNOMATCH: Speech could not be TRANSCRIBED: {}'.format(evt.result.no_match_details))\n",
    "\n",
    "    def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "        print('SessionStarted event')\n",
    "\n",
    "    def recognize_from_file():\n",
    "\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
    "        speech_config.speech_recognition_language=\"es-AR\"\n",
    "\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=archivo_audio)\n",
    "        conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n",
    "        transcribing_stop = False\n",
    "\n",
    "        def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "            #\"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "            print('CLOSING on {}'.format(evt))\n",
    "            nonlocal transcribing_stop\n",
    "            transcribing_stop = True\n",
    "\n",
    "        # Connect callbacks to the events fired by the conversation transcriber\n",
    "        conversation_transcriber.transcribed.connect(conversation_transcriber_transcribed_cb)\n",
    "        conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n",
    "        conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n",
    "        conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n",
    "        # stop transcribing on either session stopped or canceled events\n",
    "        conversation_transcriber.session_stopped.connect(stop_cb)\n",
    "        conversation_transcriber.canceled.connect(stop_cb)\n",
    "\n",
    "        conversation_transcriber.start_transcribing_async()\n",
    "\n",
    "        # Waits for completion.\n",
    "        while not transcribing_stop:\n",
    "            time.sleep(.5)\n",
    "        conversation_transcriber.stop_transcribing_async()    \n",
    "\n",
    "    #ejecutamos la funcion que transcribe el texto\n",
    "    recognize_from_file()\n",
    "    \n",
    "    #aca empezamos a manipular resultados\n",
    "    for i in range(len(salida)):\n",
    "        json_string = salida[i]\n",
    "        json_object = json.loads(json_string)\n",
    "        json_object[\"id_audio\"]=archivo_audio\n",
    "        json_object[\"orden\"]=i\n",
    "        dfAux=pd.json_normalize(json_object)\n",
    "        dfFinal=pd.concat([dfFinal, dfAux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7fd9fd13-8f0c-4913-9a59-1c4915d3c6ca",
   "metadata": {
    "id": "7fd9fd13-8f0c-4913-9a59-1c4915d3c6ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfFinal=dfFinal.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "43e07a47-6eea-4d6f-8af3-db8bf64ff309",
   "metadata": {
    "id": "43e07a47-6eea-4d6f-8af3-db8bf64ff309",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiempo_original</th>\n",
       "      <th>tiempo_modificado</th>\n",
       "      <th>nombre_archivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>caso CAS-11558573-G8H5C1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>caso CAS-11560264-Y1D9M5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>caso CAS-11560748-B8S2G5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>Caso CAS-11567570-V0L9L8.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>caso CAS-11569288-L9M3L3.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tiempo_original  tiempo_modificado                nombre_archivo\n",
       "0              223                223  caso CAS-11558573-G8H5C1.wav\n",
       "1              113                113  caso CAS-11560264-Y1D9M5.wav\n",
       "2               77                 77  caso CAS-11560748-B8S2G5.wav\n",
       "3               61                 61  Caso CAS-11567570-V0L9L8.wav\n",
       "4              126                126  caso CAS-11569288-L9M3L3.wav"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTiempos=pd.DataFrame(lista_tiempos, columns=[\"tiempo_original\", \"tiempo_modificado\", \"nombre_archivo\"])\n",
    "dfTiempos.tiempo_original=dfTiempos.tiempo_original.astype(int)\n",
    "dfTiempos.tiempo_modificado=dfTiempos.tiempo_modificado.astype(int)\n",
    "dfTiempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5df76025-d680-4907-b343-0f984374be0f",
   "metadata": {
    "id": "5df76025-d680-4907-b343-0f984374be0f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfFinal=dfResultados.copy()\n",
    "lista=[]\n",
    "#tengo que recorrer todos los audios\n",
    "for x in lista_archivos:\n",
    "    df= pd.DataFrame()\n",
    "    df=dfFinal.loc[dfFinal.id_audio==x].copy().reset_index(drop=True)\n",
    "\n",
    "    # Creo una nueva columna 'Grouped_Text' que contiene los mensajes agrupados por Speaker\n",
    "    df['Grouped_Text'] = (df['Speaker'] != df['Speaker'].shift(1)).cumsum()\n",
    "    df = df.groupby(['Speaker', 'Grouped_Text'])['Text'].apply(' '.join).reset_index()\n",
    "    \n",
    "    #ordeno los mensajes agrupados\n",
    "    df.sort_values(by=[\"Grouped_Text\"], ascending =True)\n",
    "    \n",
    "    #le asigno el nombre del audio a estos mensajes agrupados\n",
    "    df[\"id_audio\"]=x\n",
    "    df.rename(columns={\"Grouped_Text\":\"Orden\"}, inplace=True)\n",
    "    \n",
    "    #guardamos los resultados en una lista auxiliar\n",
    "    lista.append(df.values.tolist())\n",
    "    \n",
    "#dejamos todo en un dataframe final\n",
    "dfAux=pd.DataFrame()\n",
    "dfFinal2=pd.DataFrame()\n",
    "for y in range(len(lista)):\n",
    "    for x in range(len(lista[y])):\n",
    "        dfAux = pd.DataFrame(lista[y][x]).T\n",
    "        dfFinal2=pd.concat([dfAux, dfFinal2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3a7b264f-8104-4f10-beb3-abf25e8ce620",
   "metadata": {
    "id": "3a7b264f-8104-4f10-beb3-abf25e8ce620",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfFinal2.rename(columns={0:\"Speaker\", 1:\"Orden\", 2:\"Texto\", 3:\"id_audio\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a3774588-87c1-476d-a7ca-d0e3a299a94c",
   "metadata": {
    "id": "a3774588-87c1-476d-a7ca-d0e3a299a94c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfFinal2.to_csv(\"salida_prueba_resumida.csv\", sep=\"|\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c15469-5b5c-4cd2-b25d-b64c1c1bcd19",
   "metadata": {
    "id": "79c15469-5b5c-4cd2-b25d-b64c1c1bcd19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033f77e-5752-4f0c-996e-b1d0acdf6194",
   "metadata": {
    "id": "c033f77e-5752-4f0c-996e-b1d0acdf6194"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cfe294-9f51-4f04-aa79-e9955e696b67",
   "metadata": {
    "id": "70cfe294-9f51-4f04-aa79-e9955e696b67"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
